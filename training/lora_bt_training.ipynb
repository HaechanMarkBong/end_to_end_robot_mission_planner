{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    ")\n",
    "import os, torch, wandb\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, setup_chat_format\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "426432f6925c4d7ab0d7f4ed8799790d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_dtype = torch.float16\n",
    "attn_implementation = \"eager\"\n",
    "\n",
    "# QLoRA config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "base_model = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation\n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer= AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_context</th>\n",
       "      <th>actions_dictionary</th>\n",
       "      <th>query</th>\n",
       "      <th>explanation</th>\n",
       "      <th>bt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a beach chair and umbrella on the beach (28.3m...</td>\n",
       "      <td>NavigateTo: Moves the robot to a specified tar...</td>\n",
       "      <td>Can you please bring me the bowl of soup and t...</td>\n",
       "      <td>Good, I will first locate the bowl of soup in ...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a table with chairs (21.3m)\\ntwo men standing ...</td>\n",
       "      <td>NavigateTo: Moves the robot to a specified tar...</td>\n",
       "      <td>\"Can you identify the man in the black jacket ...</td>\n",
       "      <td>In this scenario, I will first attempt to loca...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a black cow grazing in a field (54.5m)\\na man ...</td>\n",
       "      <td>NavigateTo: Moves the robot to a specified tar...</td>\n",
       "      <td>\"Can you locate the person standing in front o...</td>\n",
       "      <td>In this scenario, I will attempt to locate the...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a blur of a person walking on a street (13.5m)...</td>\n",
       "      <td>NavigateTo: Moves the robot to a specified tar...</td>\n",
       "      <td>\"Can you display a message on the laptop to re...</td>\n",
       "      <td>I will start by attempting to display a messag...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a group of men playing frc (64.7m)\\na polar be...</td>\n",
       "      <td>NavigateTo: Moves the robot to a specified tar...</td>\n",
       "      <td>\"Can you take the bowl filled with fruit and i...</td>\n",
       "      <td>I will first check if there is a bowl filled w...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      object_context  \\\n",
       "0  a beach chair and umbrella on the beach (28.3m...   \n",
       "1  a table with chairs (21.3m)\\ntwo men standing ...   \n",
       "2  a black cow grazing in a field (54.5m)\\na man ...   \n",
       "3  a blur of a person walking on a street (13.5m)...   \n",
       "4  a group of men playing frc (64.7m)\\na polar be...   \n",
       "\n",
       "                                  actions_dictionary  \\\n",
       "0  NavigateTo: Moves the robot to a specified tar...   \n",
       "1  NavigateTo: Moves the robot to a specified tar...   \n",
       "2  NavigateTo: Moves the robot to a specified tar...   \n",
       "3  NavigateTo: Moves the robot to a specified tar...   \n",
       "4  NavigateTo: Moves the robot to a specified tar...   \n",
       "\n",
       "                                               query  \\\n",
       "0  Can you please bring me the bowl of soup and t...   \n",
       "1  \"Can you identify the man in the black jacket ...   \n",
       "2  \"Can you locate the person standing in front o...   \n",
       "3  \"Can you display a message on the laptop to re...   \n",
       "4  \"Can you take the bowl filled with fruit and i...   \n",
       "\n",
       "                                         explanation  \\\n",
       "0  Good, I will first locate the bowl of soup in ...   \n",
       "1  In this scenario, I will first attempt to loca...   \n",
       "2  In this scenario, I will attempt to locate the...   \n",
       "3  I will start by attempting to display a messag...   \n",
       "4  I will first check if there is a bowl filled w...   \n",
       "\n",
       "                                                  bt  \n",
       "0  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "1  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "2  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "3  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "4  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json(\"../data/queries_dataset.json\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful robot assistant named Goat that can answer questions or execute actions by generating a behavior tree.\n",
      "\n",
      "Object Context : \n",
      "a beach chair and umbrella on the beach (28.3m)\n",
      "a woman walking down the street with an umbrella (96.9m)\n",
      "a blur of a person in a classroom (95.0m)\n",
      "\n",
      "Actions Dictionary:\n",
      "NavigateTo: Moves the robot to a specified target (e.g., location or object). (Arguments: target)\n",
      "Pick: Picks up a specified object. (Arguments: object)\n",
      "Place: Places an object at a specified location. (Arguments: object, location)\n",
      "LocateObject: Searches for a specified object in the environment. (Arguments: object)\n",
      "RequestAssistance: Requests help for a specific task. (Arguments: task)\n",
      "Wait: Waits for a specified amount of time. (Arguments: duration)\n",
      "ExecuteCommand: Runs a specified bash or system command. (Arguments: command)\n",
      "Communicate: Sends a message to a user or another robot. (Arguments: message)\n",
      "RunDiagnostics: Runs system diagnostics to check for issues. (Arguments: )\n",
      "MoveForward: Moves the robot forward by a specified distance. (Arguments: distance)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are a helpful robot assistant named Goat t...</td>\n",
       "      <td>Can you please bring me the bowl of soup and t...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are a helpful robot assistant named Goat t...</td>\n",
       "      <td>\"Can you identify the man in the black jacket ...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are a helpful robot assistant named Goat t...</td>\n",
       "      <td>\"Can you locate the person standing in front o...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are a helpful robot assistant named Goat t...</td>\n",
       "      <td>\"Can you display a message on the laptop to re...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are a helpful robot assistant named Goat t...</td>\n",
       "      <td>\"Can you take the bowl filled with fruit and i...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0  You are a helpful robot assistant named Goat t...   \n",
       "1  You are a helpful robot assistant named Goat t...   \n",
       "2  You are a helpful robot assistant named Goat t...   \n",
       "3  You are a helpful robot assistant named Goat t...   \n",
       "4  You are a helpful robot assistant named Goat t...   \n",
       "\n",
       "                                               input  \\\n",
       "0  Can you please bring me the bowl of soup and t...   \n",
       "1  \"Can you identify the man in the black jacket ...   \n",
       "2  \"Can you locate the person standing in front o...   \n",
       "3  \"Can you display a message on the laptop to re...   \n",
       "4  \"Can you take the bowl filled with fruit and i...   \n",
       "\n",
       "                                              output  \n",
       "0  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "1  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "2  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "3  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "4  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_context = data['object_context']\n",
    "actions_dictionary = data['actions_dictionary']\n",
    "query = data['query']\n",
    "explanation = data['explanation']\n",
    "bt = data['bt']\n",
    "\n",
    "\n",
    "# Create df with the following columns: instruction, input, output\n",
    "def formatting_input(examples):\n",
    "    instruction = \"\"\"You are a helpful robot assistant named Goat that can answer questions or execute actions by generating a behavior tree.\n",
    "\n",
    "Object Context : \n",
    "{object_context}\n",
    "\n",
    "Actions Dictionary:\n",
    "{actions_dictionary}\n",
    "\"\"\"\n",
    "\n",
    "    instruction = instruction.format(object_context=examples['object_context'], actions_dictionary=examples['actions_dictionary'])\n",
    "    return instruction\n",
    "\n",
    "for i in range(len(data)):\n",
    "    instruction = formatting_input(data.iloc[i])\n",
    "    print(instruction)\n",
    "    break\n",
    "\n",
    "formatted_data = pd.DataFrame({\n",
    "    'instruction': instruction,\n",
    "    'input': query,\n",
    "    'output': bt,\n",
    "})\n",
    "\n",
    "formatted_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e46baacc78c4a5f86f5f4c68eb91968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful robot assistant named Goat that can answer questions or execute actions by generating a behavior tree.\n",
      "\n",
      "Object Context : \n",
      "a beach chair and umbrella on the beach (28.3m)\n",
      "a woman walking down the street with an umbrella (96.9m)\n",
      "a blur of a person in a classroom (95.0m)\n",
      "\n",
      "Actions Dictionary:\n",
      "NavigateTo: Moves the robot to a specified target (e.g., location or object). (Arguments: target)\n",
      "Pick: Picks up a specified object. (Arguments: object)\n",
      "Place: Places an object at a specified location. (Arguments: object, location)\n",
      "LocateObject: Searches for a specified object in the environment. (Arguments: object)\n",
      "RequestAssistance: Requests help for a specific task. (Arguments: task)\n",
      "Wait: Waits for a specified amount of time. (Arguments: duration)\n",
      "ExecuteCommand: Runs a specified bash or system command. (Arguments: command)\n",
      "Communicate: Sends a message to a user or another robot. (Arguments: message)\n",
      "RunDiagnostics: Runs system diagnostics to check for issues. (Arguments: )\n",
      "MoveForward: Moves the robot forward by a specified distance. (Arguments: distance)\n",
      "<|eot_id|>\n",
      "<|start_header_id|>user<|end_header_id|>\n",
      "Can you please bring me the bowl of soup and then release it on the table?<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "<root main_tree_to_execute=\"MainTree\">\n",
      "  <BehaviorTree ID=\"MainTree\">\n",
      "    <Fallback>\n",
      "      <Sequence>\n",
      "        <Action ID=\"LocateObject\" object=\"bowl_of_soup\"/>\n",
      "        <Action ID=\"NavigateTo\" target=\"bowl_of_soup\"/>\n",
      "        <Action ID=\"Pick\" object=\"bowl_of_soup\"/>\n",
      "        <Action ID=\"Place\" object=\"bowl_of_soup\" location=\"table\"/>\n",
      "      </Sequence>\n",
      "      <Action ID=\"RequestAssistance\" task=\"find_bowl_of_soup\"/>\n",
      "    </Fallback>\n",
      "  </BehaviorTree>\n",
      "</root>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_prompt = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "{}<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "{}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "{}\n",
    "\"\"\"\n",
    "\n",
    "EOS_TOKEN = \"<|eot_id|>\"\n",
    "\n",
    "def formatting_prompt(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs = examples[\"input\"]\n",
    "    outputs = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction,input_, output in zip(instructions, inputs, outputs):\n",
    "        text = data_prompt.format(instruction,input_, output)\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "\n",
    "\n",
    "# Create the dataset and apply the mapping\n",
    "training_data = Dataset.from_pandas(formatted_data)\n",
    "training_data = training_data.map(formatting_prompt, batched=True)\n",
    "\n",
    "# Display a sample for verification\n",
    "print(training_data[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/.local/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '0.13.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/simon/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/home/simon/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930536ef81e74c67823251d9110cfd68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8846675f71f348709cfffe5570ada5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:  # needed for 16 bit\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    "\n",
    "modules = find_all_linear_names(model)\n",
    "\n",
    "\n",
    "# LoRA config\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=modules\n",
    ")\n",
    "\n",
    "new_model = \"llama-3.2-1b-bt-generator\"\n",
    "\n",
    "#Hyperparamter\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=new_model,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    num_train_epochs=1,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=0.1,\n",
    "    logging_steps=1,\n",
    "    warmup_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    group_by_length=True,\n",
    "    report_to=\"wandb\"\n",
    ")\n",
    "\n",
    "# Create train/test split\n",
    "full_dataset = training_data.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "# Setting sft parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=full_dataset[\"train\"],\n",
    "    eval_dataset=full_dataset[\"test\"],\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=512,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38fe8ecc7207478e9d62f3e0cc4eed15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful robot assistant named Goat that can answer questions or execute actions by generating a behavior tree.\n",
      "\n",
      "Object Context : \n",
      "a beach chair and umbrella on the beach (28.3m)\n",
      "a woman walking down the street with an umbrella (96.9m)\n",
      "a blur of a person in a classroom (95.0m)\n",
      "\n",
      "Actions Dictionary:\n",
      "NavigateTo: Moves the robot to a specified target (e.g., location or object). (Arguments: target)\n",
      "Pick: Picks up a specified object. (Arguments: object)\n",
      "Place: Places an object at a specified location. (Arguments: object, location)\n",
      "LocateObject: Searches for a specified object in the environment. (Arguments: object)\n",
      "RequestAssistance: Requests help for a specific task. (Arguments: task)\n",
      "Wait: Waits for a specified amount of time. (Arguments: duration)\n",
      "ExecuteCommand: Runs a specified bash or system command. (Arguments: command)\n",
      "Communicate: Sends a message to a user or another robot. (Arguments: message)\n",
      "RunDiagnostics: Runs system diagnostics to check for issues. (Arguments: )\n",
      "MoveForward: Moves the robot forward by a specified distance. (Arguments: distance)\n",
      "<|eot_id|>\n",
      "<|start_header_id|>user<|end_header_id|>\n",
      "Can you please bring me the bowl of soup and then release it on the table?<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "<root main_tree_to_execute=\"MainTree\">\n",
      "  <BehaviorTree ID=\"MainTree\">\n",
      "    <Fallback>\n",
      "      <Sequence>\n",
      "        <Action ID=\"LocateObject\" object=\"bowl_of_soup\"/>\n",
      "        <Action ID=\"NavigateTo\" target=\"bowl_of_soup\"/>\n",
      "        <Action ID=\"Pick\" object=\"bowl_of_soup\"/>\n",
      "        <Action ID=\"Place\" object=\"bowl_of_soup\" location=\"table\"/>\n",
      "      </Sequence>\n",
      "      <Action ID=\"RequestAssistance\" task=\"find_bowl_of_soup\"/>\n",
      "    </Fallback>\n",
      "  </BehaviorTree>\n",
      "</root>\n"
     ]
    }
   ],
   "source": [
    "data_prompt = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "{}<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "{}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = \"<|eot_id|>\"\n",
    "\n",
    "def formatting_prompt(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs = examples[\"input\"]\n",
    "    outputs = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction,input_, output in zip(instructions, inputs, outputs):\n",
    "        text = data_prompt.format(instruction,input_, output)\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "\n",
    "\n",
    "# Create the dataset and apply the mapping\n",
    "training_data = Dataset.from_pandas(formatted_data)\n",
    "training_data = training_data.map(formatting_prompt, batched=True)\n",
    "\n",
    "# Display a sample for verification\n",
    "print(training_data[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer of the question is: \n",
      "I will first LocateObject to find the bowl of soup, then Pick it up, and finally Place it on the table.\n",
      "\n",
      "Executing the behavior tree:\n",
      "\n",
      "1. LocateObject: The robot searches for the bowl of soup and finds it 12.5 meters away from the current location.\n",
      "2. Pick: The robot picks up the bowl of soup.\n",
      "3. Place: The robot moves the bowl of soup to the table, which is 10.2 meters away from the current location.\n",
      "\n",
      "The bowl of soup has been placed on the table.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "instructions = training_data[\"instruction\"][0]\n",
    "inputs = training_data[\"input\"][0]\n",
    "outputs = training_data[\"output\"][0]\n",
    "text = data_prompt.format(instructions, inputs, \"\")\n",
    "\n",
    "inputs = tokenizer([\n",
    "    text\n",
    "], return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
    "\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 2020, use_cache = True)\n",
    "\n",
    "answer=tokenizer.batch_decode(outputs)\n",
    "answer=answer[0].split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1]\n",
    "print(\"Answer of the question is:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msimonroy99\u001b[0m (\u001b[33msimonroy99-cole-de-technologie-sup-rieure\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/simon/workspace/ETS/SYS819/proteus/training/wandb/run-20241202_222421-kqyzu2dd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface/runs/kqyzu2dd' target=\"_blank\">llama-3.2-1b-bt-generator</a></strong> to <a href='https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface' target=\"_blank\">https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface/runs/kqyzu2dd' target=\"_blank\">https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface/runs/kqyzu2dd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164d2c70810a4982bc4b91ecfd793ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1894, 'grad_norm': 1.6201972961425781, 'learning_rate': 2e-05, 'epoch': 0.02}\n",
      "{'loss': 2.1813, 'grad_norm': 1.6012827157974243, 'learning_rate': 4e-05, 'epoch': 0.04}\n",
      "{'loss': 2.2726, 'grad_norm': 1.7221444845199585, 'learning_rate': 6e-05, 'epoch': 0.07}\n",
      "{'loss': 2.1768, 'grad_norm': 1.3966100215911865, 'learning_rate': 8e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1294, 'grad_norm': 1.3764113187789917, 'learning_rate': 0.0001, 'epoch': 0.11}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194547fab26541db84b0dc7b130ce512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1767985820770264, 'eval_runtime': 2.7342, 'eval_samples_per_second': 3.657, 'eval_steps_per_second': 3.657, 'epoch': 0.11}\n",
      "{'loss': 1.9975, 'grad_norm': 1.3908041715621948, 'learning_rate': 0.00012, 'epoch': 0.13}\n",
      "{'loss': 1.7899, 'grad_norm': 1.3077309131622314, 'learning_rate': 0.00014, 'epoch': 0.16}\n",
      "{'loss': 1.7414, 'grad_norm': 1.2258648872375488, 'learning_rate': 0.00016, 'epoch': 0.18}\n",
      "{'loss': 1.788, 'grad_norm': 1.2204052209854126, 'learning_rate': 0.00018, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6082, 'grad_norm': 1.3803640604019165, 'learning_rate': 0.0002, 'epoch': 0.22}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9265cf88a9ef45e9b736a297d2fb20c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2180795669555664, 'eval_runtime': 2.7394, 'eval_samples_per_second': 3.65, 'eval_steps_per_second': 3.65, 'epoch': 0.22}\n",
      "{'loss': 1.4081, 'grad_norm': 1.5150755643844604, 'learning_rate': 0.0001942857142857143, 'epoch': 0.24}\n",
      "{'loss': 0.9233, 'grad_norm': 1.1450833082199097, 'learning_rate': 0.00018857142857142857, 'epoch': 0.27}\n",
      "{'loss': 0.7325, 'grad_norm': 1.3565088510513306, 'learning_rate': 0.00018285714285714286, 'epoch': 0.29}\n",
      "{'loss': 0.5198, 'grad_norm': 1.4325248003005981, 'learning_rate': 0.00017714285714285713, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4745, 'grad_norm': 1.2779836654663086, 'learning_rate': 0.00017142857142857143, 'epoch': 0.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163fd9094c004d0c87f89720c06f3848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.41321858763694763, 'eval_runtime': 2.7444, 'eval_samples_per_second': 3.644, 'eval_steps_per_second': 3.644, 'epoch': 0.33}\n",
      "{'loss': 0.388, 'grad_norm': 1.1452417373657227, 'learning_rate': 0.00016571428571428575, 'epoch': 0.36}\n",
      "{'loss': 0.3778, 'grad_norm': 0.9504296183586121, 'learning_rate': 0.00016, 'epoch': 0.38}\n",
      "{'loss': 0.3105, 'grad_norm': 0.8331438302993774, 'learning_rate': 0.0001542857142857143, 'epoch': 0.4}\n",
      "{'loss': 0.3664, 'grad_norm': 1.0127973556518555, 'learning_rate': 0.00014857142857142857, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3251, 'grad_norm': 0.7706222534179688, 'learning_rate': 0.00014285714285714287, 'epoch': 0.44}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1979ba6ed4bf4234a30bf2ca5cf1639a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.30148670077323914, 'eval_runtime': 2.729, 'eval_samples_per_second': 3.664, 'eval_steps_per_second': 3.664, 'epoch': 0.44}\n",
      "{'loss': 0.4266, 'grad_norm': 0.7881426215171814, 'learning_rate': 0.00013714285714285716, 'epoch': 0.47}\n",
      "{'loss': 0.3624, 'grad_norm': 0.7252787351608276, 'learning_rate': 0.00013142857142857143, 'epoch': 0.49}\n",
      "{'loss': 0.3488, 'grad_norm': 0.7622185349464417, 'learning_rate': 0.00012571428571428572, 'epoch': 0.51}\n",
      "{'loss': 0.2866, 'grad_norm': 0.6837682723999023, 'learning_rate': 0.00012, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2752, 'grad_norm': 0.5877801775932312, 'learning_rate': 0.00011428571428571428, 'epoch': 0.56}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203ddcb229d445a18157e5a25fb1b895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2635095715522766, 'eval_runtime': 2.7523, 'eval_samples_per_second': 3.633, 'eval_steps_per_second': 3.633, 'epoch': 0.56}\n",
      "{'loss': 0.2712, 'grad_norm': 0.5325076580047607, 'learning_rate': 0.00010857142857142856, 'epoch': 0.58}\n",
      "{'loss': 0.2616, 'grad_norm': 0.5475583672523499, 'learning_rate': 0.00010285714285714286, 'epoch': 0.6}\n",
      "{'loss': 0.271, 'grad_norm': 0.6213672161102295, 'learning_rate': 9.714285714285715e-05, 'epoch': 0.62}\n",
      "{'loss': 0.3059, 'grad_norm': 0.6089926362037659, 'learning_rate': 9.142857142857143e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3026, 'grad_norm': 0.5666790008544922, 'learning_rate': 8.571428571428571e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12c6810d7944574870a6d00fd472d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2587767541408539, 'eval_runtime': 2.7421, 'eval_samples_per_second': 3.647, 'eval_steps_per_second': 3.647, 'epoch': 0.67}\n",
      "{'loss': 0.34, 'grad_norm': 0.6252342462539673, 'learning_rate': 8e-05, 'epoch': 0.69}\n",
      "{'loss': 0.2881, 'grad_norm': 0.5597185492515564, 'learning_rate': 7.428571428571429e-05, 'epoch': 0.71}\n",
      "{'loss': 0.2358, 'grad_norm': 0.5354404449462891, 'learning_rate': 6.857142857142858e-05, 'epoch': 0.73}\n",
      "{'loss': 0.3269, 'grad_norm': 0.6313555240631104, 'learning_rate': 6.285714285714286e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3039, 'grad_norm': 0.5774863362312317, 'learning_rate': 5.714285714285714e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2824e99bca44be8f9c6ea4a8286484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.25044459104537964, 'eval_runtime': 2.7383, 'eval_samples_per_second': 3.652, 'eval_steps_per_second': 3.652, 'epoch': 0.78}\n",
      "{'loss': 0.2958, 'grad_norm': 0.5137229561805725, 'learning_rate': 5.142857142857143e-05, 'epoch': 0.8}\n",
      "{'loss': 0.2685, 'grad_norm': 0.5047869682312012, 'learning_rate': 4.5714285714285716e-05, 'epoch': 0.82}\n",
      "{'loss': 0.2126, 'grad_norm': 0.5422986149787903, 'learning_rate': 4e-05, 'epoch': 0.84}\n",
      "{'loss': 0.2734, 'grad_norm': 0.6266900300979614, 'learning_rate': 3.428571428571429e-05, 'epoch': 0.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2931, 'grad_norm': 0.537534773349762, 'learning_rate': 2.857142857142857e-05, 'epoch': 0.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6c067b49fb400c8ab467a285f78b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24703288078308105, 'eval_runtime': 2.7403, 'eval_samples_per_second': 3.649, 'eval_steps_per_second': 3.649, 'epoch': 0.89}\n",
      "{'loss': 0.2733, 'grad_norm': 0.5661378502845764, 'learning_rate': 2.2857142857142858e-05, 'epoch': 0.91}\n",
      "{'loss': 0.3327, 'grad_norm': 0.5771268606185913, 'learning_rate': 1.7142857142857145e-05, 'epoch': 0.93}\n",
      "{'loss': 0.2696, 'grad_norm': 0.5509576201438904, 'learning_rate': 1.1428571428571429e-05, 'epoch': 0.96}\n",
      "{'loss': 0.2535, 'grad_norm': 0.5186552405357361, 'learning_rate': 5.7142857142857145e-06, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2936, 'grad_norm': 0.5627044439315796, 'learning_rate': 0.0, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bdf599981bd487da9fcc79e3339e195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2461223155260086, 'eval_runtime': 2.7472, 'eval_samples_per_second': 3.64, 'eval_steps_per_second': 3.64, 'epoch': 1.0}\n",
      "{'train_runtime': 82.421, 'train_samples_per_second': 1.092, 'train_steps_per_second': 0.546, 'train_loss': 0.7349574612246619, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=45, training_loss=0.7349574612246619, metrics={'train_runtime': 82.421, 'train_samples_per_second': 1.092, 'train_steps_per_second': 0.546, 'total_flos': 645761559625728.0, 'train_loss': 0.7349574612246619, 'epoch': 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer of the question is: \n",
      "<root main_tree_to_execute=\"MainTree\">\n",
      "  <BehaviorTree ID=\"MainTree\">\n",
      "    <Fallback>\n",
      "      <Sequence>\n",
      "        <Action ID=\"LocateObject\" object=\"bowl_of_soup\"/>\n",
      "        <Action ID=\"Pick\" object=\"bowl_of_soup\"/>\n",
      "        <Action ID=\"Place\" object=\"bowl_of_soup\" location=\"table\"/>\n",
      "      </Sequence>\n",
      "      <Sequence>\n",
      "        <Action ID=\"RequestAssistance\" task=\"locate_bowl_of_soup\"/>\n",
      "      </Sequence>\n",
      "    </Fallback>\n",
      "  </BehaviorTree>\n",
      "</root>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer([\n",
    "    text\n",
    "], return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
    "\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 2020, use_cache = True)\n",
    "\n",
    "answer=tokenizer.batch_decode(outputs)\n",
    "answer=answer[0].split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1].split(EOS_TOKEN)[0]\n",
    "print(\"Answer of the question is:\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
